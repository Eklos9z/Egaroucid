<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/Nyanyan/Egaroucid/main/img/favicon.ico">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="style.css">
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:site" content="@takuto_yamana" />
<link rel="alternate" hreflang="en" href="https://www.egaroucid.nyanyan.dev/en/technology/"/>
<link rel="alternate" hreflang="x-default" href="https://www.egaroucid.nyanyan.dev/en/technology/">
<meta property="og:image" content="https://www.egaroucid.nyanyan.dev/ja/technology/img/eyecatch.png" />
<meta property="og:url" content="https://www.egaroucid.nyanyan.dev/ja/technology/" />
<meta property="og:title" content="技術 Egaroucid" />
<meta property="og:description" content="オセロAI Egaroucid 世界最強レベルのオセロAI Egaroucid を搭載したフリーソフトウェアです。搭載AIはコンテストで世界1位になった自作AIをベースに改良したものです。" />
<link rel="canonical" href="https://www.egaroucid.nyanyan.dev/ja/technology/">
<meta name="description" content="オセロAI Egaroucid 世界最強レベルのオセロAI Egaroucid を搭載したフリーソフトウェアです。搭載AIはコンテストで世界1位になった自作AIをベースに改良したものです。"/>
<title>技術 Egaroucid</title>
</head>
<body>
<div class="menu_bar">
<div class="menu_button"><a class="menu_a" href="https://www.egaroucid.nyanyan.dev/ja/">ホーム</a></div><div class="menu_button"><a class="menu_a" href="https://www.egaroucid.nyanyan.dev/ja/download/">ダウンロード</a></div><div class="menu_button"><a class="menu_a" href="https://www.egaroucid.nyanyan.dev/ja/console/">コンソール版</a></div><div class="menu_button"><a class="menu_a" href="https://www.egaroucid.nyanyan.dev/ja/web/">Web版</a></div><div class="menu_button"><a class="menu_a" href="https://www.egaroucid.nyanyan.dev/ja/benchmarks/">ベンチマーク</a></div><div class="menu_button"><a class="menu_a" href="https://docs.google.com/forms/d/e/1FAIpQLSd6ML1T1fc707luPEefBXuImMnlM9cQP8j-YHKiSyFoS-8rmQ/viewform?usp=sf_link" target="_blank" el=”noopener noreferrer”>バグ報告</div></a>
<div class="menu_button"><a class="menu_a" href="https://nyanyan.dev/ja/" target="_blank" el=”noopener noreferrer”>作者</div></a>
</div>
<div class="box">
<p></p>
<a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-text="技術 Egaroucid - 最強レベルオセロAI" data-url="https://www.egaroucid.nyanyan.dev/ja/technology" data-hashtags="egaroucid" data-related="takuto_yamana" data-show-count="false"><span>Tweet</span></a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
<a href="https://www.egaroucid.nyanyan.dev/en/technology">English</a> 
<p><h1>Egaroucid 技術資料</h1></p><p></p><p><b>ここに書いた内容は高度なものです。一般的なアルゴリズムの話はしません。オセロAI初心者向け記事は<a href="https://note.com/nyanyan_cubetech/m/m54104c8d2f12" target="_blank" el=”noopener noreferrer”>こちら</a>に書きました。</b></p><p></p><p>このページは日本語のみで、のんびりと気が向いたときに書き足していきます。</p><p></p><p></p><p></p><p><h2>minimaxかMCTSか</h2></p><p></p><p>ゲームAIを作る上でのアルゴリズムは古くからminimax法が有名でした。1997年にチェスで人間を打ち負かしたDeep Blueも、同年にオセロで人間を打ち負かしたLogistelloも、このminimax法から派生するアルゴリズムでした。しかし、2000年に入るとMCTS(モンテカルロ木探索)が発展し、さらに2010年代にはMCTSをさらにアップデートしたPV-MCTS (Policy Value MCTS)が発展しました。2016年に囲碁で人間を打ち負かしたAlphaGoはPV-MCTSです。</p><p></p><p>この2つのアルゴリズムは根本から違うものです。将棋AIでは聞くところによるとすでにPV-MCTS優勢(2022年現在の伝聞)だそうですが、オセロにおいてはどちらを使うのが良いでしょうか。</p><p></p><p>オセロにおいてminimax系統が良いのかMCTS系統が良いのかは、まだ断言できないと思います。ですが、私はEgaroucidに対してminimax法から派生したNegascout法を利用しました。この理由について、軽くまとめます。</p><p></p><p></p><p></p><p><h3> オセロでは精度の高い評価関数を簡単に作れるから</h3></p><p></p><p>minimax法では、計算量の問題で終局まで読みきれない場合には終局前に評価関数を使って、それをそのまま終局まで読んだ確定値と同じように利用します。つまり、評価関数の精度が悪ければ必然的にAIは弱くなります。</p><p></p><p>囲碁では評価関数が作りにくいようで、そのために評価関数を使わなくて済むMCTSが発展したそうです。</p><p></p><p>オセロにおいては、Logistelloに関する論文「Experiments with Multi-ProbCut and a New High-Quality Evaluation Function for Othello」でパターンを用いた評価関数が提案されてから、(それなりに)手軽に高精度の評価関数が作れるようになりました。ですので、この方法を踏襲すれば良かったわけです。</p><p></p><p><h3> オセロは合法手数が比較的少ないから</h3></p><p></p><p>MCTSは評価関数を必要としない以外にも利点があります。それは、合法手が多いゲームでもそれなりの性能が出せるところです。オセロは局面1つに対して概ね10手前後の合法手しかありませんが、例えば囲碁はとんでもないことになります。</p><p></p><p>各局面の合法手数をb、探索する深さをdとすると、minimax法の計算量はb^d、そしてminimax法に効果的な枝刈りを施したαβ法はsqrt(b^d)です。これでは、合法手が多いゲームでは計算量が爆発しやすくなって困ります。</p><p></p><p>しかし、オセロに関して言えばこの問題は囲碁などのゲームと比較して大きくありません。</p><p></p><p><h3> 実験してみてあまり強くならなかったから</h3></p><p></p><p><a href="https://www.codingame.com/multiplayer/bot-programming/othello-1" target="_blank" el=”noopener noreferrer”>CodinGame Othello</a>というオセロAIのコンテストに参加しているときに、minimaxとMCTSを両方試してみたのですが、どうも私の実装ではMCTSがあまり強くなりませんでした。あくまでも私の実装力の範囲の話なので、本当にオセロにMCTSが向いていないのかを議論することはできませんが、とりあえずminimaxを使おうという結論になりました。</p><p></p><p><h3> 完全読みの実装に繋げたいから</h3></p><p></p><p>Egaroucidでは終盤の決められた手数で完全読みをしてしまいます。完全読みはその名の通り、終局まで完璧に読み切ってしまうことですが、これはminimax系統のアルゴリズムで行います。Egaroucidでは完全読みの際、完全読み以前の探索結果を使うことで探索の高速化を実現しています。中盤探索をMCTSで作るとこのあたりの実装が多少煩雑になることが想像できます。</p><p></p><p></p><p></p><p><h2>評価関数</h2></p><p></p><p>既存の強豪オセロAIに広く使われているパターン評価は、Logistelloで提案され、今日のEdaxまでほとんど形を変えずに受け継がれています。Egaroucidもこのパターン評価をベースにしていますが、少し特徴量を追加しました。</p><p></p><p>Egaroucidでは石自体をパターンとして評価する既存手法に加え、合法手をパターン化したもの、追加の特徴量の全ての得点の和を評価値としました。</p><p></p><p>評価関数は2手を1つのフェーズとして合計30フェーズ用意し、それぞれ大量の学習データを用意し、確率的勾配降下法で最適化しました。</p><p></p><p><h3> 石評価パターン</h3></p><p></p><p>盤面のパターンとして使ったのは以下です。</p><p></p><div class="centering_box">    <img class="pic2" src="img/pattern.png"></div><h3> 合法手評価パターン</h3>Egaroucidでは独自の評価パターンとして、合法手のパターンを用いています。両手番の合法手か否かの情報を1マスにつき2bitで割り当て、8マスをセットにしてパターンとしています。<div class="centering_box">    <img class="pic2" src="img/legal_pattern.png"></div><h3> その他の特徴量</h3>Egaroucidではさらに、それぞれの手番について以下の項目を計算し、特徴量に追加しました。<ul>    <li>石が空きマスに接している数</li>    <li>合法手数</li>    <li>石数</li></ul><h2>並列化</h2>minimax系統のアルゴリズムはαβ法(αβ枝刈り)という手法で大幅な枝刈りを行えますが、これは逐次的に探索することを前提とした枝刈りなので、探索を並列化する場合には枝刈り効率が落ちないように注意する必要があります。EgaroucidではYBWC(Young Brothers Wait Concept)を用いてCPUを使った並列化を行いました。<h2>定数倍高速化</h2>minimax系統のアルゴリズムを使ったオセロAIはアルゴリズムの性質上、深く読むと深さに従って指数的に計算量が増大します。計算量自体を根底から改善することは不可能なので、ここで大事なのが定数倍の高速化です。Egaroucidでは、ビットボードによる高速化や、SIMDを使った高速化、さらに最終盤の探索は空きマス数に応じて専用関数を使った最適化を行うなどして定数倍高速化に努めました。<p></p>
</div>
</body>
<div class="footer">
    <p>オセロ・Othelloは登録商標です。</p>
    <p>© 2021-2023 Takuto Yamana</div></p>
</div>
</html>
